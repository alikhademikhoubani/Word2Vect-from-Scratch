{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11823844,"sourceType":"datasetVersion","datasetId":7427393}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom collections import defaultdict\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:57:10.503677Z","iopub.execute_input":"2025-05-15T13:57:10.504472Z","iopub.status.idle":"2025-05-15T13:57:10.509320Z","shell.execute_reply.started":"2025-05-15T13:57:10.504442Z","shell.execute_reply":"2025-05-15T13:57:10.508168Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"class Vocabulary:\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = {}\n        self.word_count = defaultdict(int)\n        self.total_words = 0\n        self.vocab_size = 0\n\n    def build_vocab(self, sentences, min_count = 2):\n        for word in sentences:\n            self.word_count[word] += 1\n\n        idx = 0\n        for word, count in self.word_count.items():\n            if count >= min_count:\n                self.word2idx.update({word: idx})\n                idx += 1\n    \n        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n        self.vocab_size = len(self.word2idx)\n        self.total_words = sum([count for word, count in self.word_count.items() if count >= min_count])\n\n    def word_to_index(self, word):\n        return self.word2idx.get(word, -1)\n\n    def index_to_word(self, index):\n        return self.idx2word.get(index, None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T11:48:57.471806Z","iopub.execute_input":"2025-05-15T11:48:57.472269Z","iopub.status.idle":"2025-05-15T11:48:57.483045Z","shell.execute_reply.started":"2025-05-15T11:48:57.472233Z","shell.execute_reply":"2025-05-15T11:48:57.481918Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def generate_training_data(vocab, sentences, window_size = 2):\n    training_data = []\n    sentence_indices = [vocab.word_to_index(word) for word in sentences if vocab.word_to_index(word) != -1]\n\n    for center_idx, center_word in enumerate(sentence_indices):\n        context_start = max(0, center_idx - window_size)\n        context_end = min(len(sentence_indices), center_idx + window_size + 1)\n\n        for context_idx in range(context_start, context_end):\n            if context_idx != center_idx:\n                context_word = sentence_indices[context_idx]\n                training_data.append((center_word, context_word))\n\n    return np.array(training_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:27:08.407031Z","iopub.execute_input":"2025-05-15T13:27:08.408260Z","iopub.status.idle":"2025-05-15T13:27:08.415231Z","shell.execute_reply.started":"2025-05-15T13:27:08.408210Z","shell.execute_reply":"2025-05-15T13:27:08.414080Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class Word2Vec:\n    def __init__(self, vocab_size, embed_size = 100, learning_rate = 0.001):\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.learning_rate = learning_rate\n\n        self.W = np.random.uniform(-0.5, 0.5, (vocab_size, embed_size))\n        self.W_prime = np.random.uniform(-0.5, 0.5, (embed_size, vocab_size))\n\n    def softmax(self, x):\n        exp_x = np.exp(x - np.max(x))\n        return exp_x / np.sum(exp_x)\n\n    def train(self, training_data, epochs = 1000):\n        for epoch in range(epochs):\n            loss = 0\n            for center_word, context_word in training_data:\n                h = self.W[center_word]\n                u = np.dot(h, self.W_prime)\n                y_pred = self.softmax(u)\n\n                y_true = np.zeros(self.vocab_size)\n                y_true[context_word] = 1\n\n                error = y_pred - y_true\n\n                self.W_prime -= self.learning_rate * np.outer(h, error)\n                self.W[center_word] -= self.learning_rate * np.dot(self.W_prime, error)\n\n                loss -= np.log(y_pred[context_word])\n\n            if epoch % 100 == 0:\n                print(f'Epoch {epoch}, Loss: {loss}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:27:08.989230Z","iopub.execute_input":"2025-05-15T13:27:08.990110Z","iopub.status.idle":"2025-05-15T13:27:08.999252Z","shell.execute_reply.started":"2025-05-15T13:27:08.990070Z","shell.execute_reply":"2025-05-15T13:27:08.998009Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"with open('/kaggle/input/persianstopwords/persian.txt', 'r', encoding = 'utf-8') as f:\n    stopwords = set(f.read().splitlines())\n\ntext = \"ملکه و زن ها در کنار همسران و خانواده خود یعنی شاه و مرد ها در یک سرزمین پهناور زندگی می‌کردند شاه همیشه به مرد ها تذکر میداد که قدرت در اتحاد مرد ها و شاه نهفته است و در این قلمرو ملکه به زن ها یادآوری می‌کرد که همبستگی زن ها و ملکه مهم است و در این داستان هر مرد که نزد شاه یا زن که نزد ملکه می‌آمد از آنها حکم می‌گرفت تا به دیگران کمک کنند شاه عادل و قادر بود و ملکه خردمند و زیبا و هر مرد که از حکمت شاه یا زن که از عدالت ملکه راضی نبود نزد آنها می‌رفت تا شکایت خود را مطرح کند شاه و مرد و ملکه و زن در کنار هم بودند و هیچ کس از شاه یا ملکه نمی‌ترسید شاه همیشه به زبان میاورد که مرد ها باید به یکدیگر کمک کنند و ملکه تأکید داشتند زن ها هم باید متحد باشند\"\nwords = text.split()\nfiltered_text = [word for word in words if word not in stopwords]\ncleaned_text = ' '.join(filtered_text)\nprint(cleaned_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:27:09.243968Z","iopub.execute_input":"2025-05-15T13:27:09.244361Z","iopub.status.idle":"2025-05-15T13:27:09.252907Z","shell.execute_reply.started":"2025-05-15T13:27:09.244337Z","shell.execute_reply":"2025-05-15T13:27:09.252004Z"}},"outputs":[{"name":"stdout","text":"ملکه زن همسران خانواده شاه مرد سرزمین پهناور زندگی می‌کردند شاه مرد تذکر میداد قدرت اتحاد مرد شاه نهفته قلمرو ملکه زن یادآوری می‌کرد همبستگی زن ملکه مهم داستان مرد شاه زن ملکه می‌آمد حکم می‌گرفت کمک شاه عادل قادر ملکه خردمند زیبا مرد حکمت شاه زن عدالت ملکه راضی می‌رفت شکایت مطرح شاه مرد ملکه زن شاه ملکه نمی‌ترسید شاه زبان میاورد مرد کمک ملکه تأکید زن متحد\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"vocab = Vocabulary()\nvocab.build_vocab(cleaned_text.split(' '))\ntraining_data = generate_training_data(vocab, cleaned_text.split(' '))\nword2vec_model = Word2Vec(vocab.vocab_size)\nword2vec_model.train(training_data, epochs = 1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:27:09.538768Z","iopub.execute_input":"2025-05-15T13:27:09.539150Z","iopub.status.idle":"2025-05-15T13:27:14.267891Z","shell.execute_reply.started":"2025-05-15T13:27:09.539128Z","shell.execute_reply":"2025-05-15T13:27:14.266742Z"}},"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 273.9280651175166\nEpoch 100, Loss: 181.58500756594077\nEpoch 200, Loss: 181.10085924976738\nEpoch 300, Loss: 180.9460396128876\nEpoch 400, Loss: 180.86920414258782\nEpoch 500, Loss: 180.82340062796956\nEpoch 600, Loss: 180.79319836412884\nEpoch 700, Loss: 180.77191984707156\nEpoch 800, Loss: 180.75620469921117\nEpoch 900, Loss: 180.74418136837178\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def get_word_embedding(word, vocab, model):\n    word_idx = vocab.word_to_index(word)\n    if word_idx != -1:\n        return model.W[word_idx]\n    else:\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:30:59.518810Z","iopub.execute_input":"2025-05-15T13:30:59.519248Z","iopub.status.idle":"2025-05-15T13:30:59.525083Z","shell.execute_reply.started":"2025-05-15T13:30:59.519222Z","shell.execute_reply":"2025-05-15T13:30:59.524085Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"embedding = get_word_embedding('مرد', vocab, word2vec_model)\nprint(embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:32:01.880247Z","iopub.execute_input":"2025-05-15T13:32:01.880620Z","iopub.status.idle":"2025-05-15T13:32:01.888002Z","shell.execute_reply.started":"2025-05-15T13:32:01.880597Z","shell.execute_reply":"2025-05-15T13:32:01.886709Z"}},"outputs":[{"name":"stdout","text":"[-0.11791629  0.09824163  0.16149867  0.36515609  0.27589637  0.33782451\n -0.33546593 -0.23761117 -0.37162012  0.09611822  0.46401785  0.21281058\n -0.05096967  0.39538357  0.22121418  0.21732541 -0.27843149 -0.34723499\n  0.4329129   0.51446148  0.41265543  0.35946686  0.28507072 -0.16971806\n -0.33671245 -0.41374205 -0.05198899 -0.22776971 -0.2486474   0.43918947\n -0.38915345  0.49060989 -0.23385779 -0.12272904  0.00989349  0.27630257\n -0.19655076 -0.44353416 -0.27768833  0.41741545 -0.07189619  0.10620767\n -0.39507999 -0.08934812 -0.26004592 -0.48503162  0.04088924 -0.14932115\n  0.33315881  0.2392398  -0.45263298  0.1381911  -0.42307376  0.11054123\n  0.2718077  -0.46727458 -0.16071644 -0.06832454  0.13632549 -0.37259475\n -0.19520646  0.32874091 -0.01753422  0.15881387 -0.32520808 -0.00463953\n  0.10513484  0.36069387 -0.2893219  -0.21934731 -0.24544643 -0.20634754\n  0.24809312 -0.04809858 -0.35267489  0.50107476  0.40511108  0.20499646\n -0.05248257  0.47079717  0.36123785 -0.09024045 -0.16732903  0.47147481\n  0.07493411 -0.48047779 -0.47757508 -0.0361229  -0.35211152  0.04524055\n -0.46445458  0.10548627 -0.07017472  0.22589749  0.27561419 -0.37503391\n -0.36612545  0.12234522 -0.12784797 -0.46230308]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def cosine_similarity(vec1, vec2):\n    dot_product = np.dot(vec1, vec2)\n    norm_vec1 = np.linalg.norm(vec1)\n    norm_vec2 = np.linalg.norm(vec2)\n    return dot_product / (norm_vec1 * norm_vec2)\n\ndef find_similar_words(word, vocab, model, k = 5):\n    word_idx = vocab.word_to_index(word)\n\n    if word_idx == -1:\n        return f\"Word '{word}' not in vocabulary.\"\n\n    word_vector = model.W[word_idx]\n    similarities = []\n\n    for idx in range(vocab.vocab_size):\n        if idx != word_idx:\n            other_word_vector = model.W[idx]\n            sim_score = cosine_similarity(word_vector, other_word_vector)\n            similarities.append((vocab.index_to_word(idx), sim_score))\n\n    similarities = sorted(similarities, key = lambda x: x[1], reverse = True)\n\n    return similarities[:k]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:53:33.991907Z","iopub.execute_input":"2025-05-15T13:53:33.992266Z","iopub.status.idle":"2025-05-15T13:53:34.001067Z","shell.execute_reply.started":"2025-05-15T13:53:33.992245Z","shell.execute_reply":"2025-05-15T13:53:33.999355Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"similar_words = find_similar_words(\"ملکه\", vocab, word2vec_model, k = 5)\nprint(similar_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:53:36.983208Z","iopub.execute_input":"2025-05-15T13:53:36.983593Z","iopub.status.idle":"2025-05-15T13:53:36.991367Z","shell.execute_reply.started":"2025-05-15T13:53:36.983565Z","shell.execute_reply":"2025-05-15T13:53:36.990299Z"}},"outputs":[{"name":"stdout","text":"[('شاه', 0.08961007812423587), ('مرد', 0.08729523491489555), ('زن', 0.03178485519043798), ('کمک', -0.1395635367391647)]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"def find_analogy(word_a, word_b, word_c, vocab, model):\n    # Convert words to their vector representations\n    vec_a = model.W[vocab.word_to_index(word_a)] if vocab.word_to_index(word_a) != -1 else None\n    vec_b = model.W[vocab.word_to_index(word_b)] if vocab.word_to_index(word_b) != -1 else None\n    vec_c = model.W[vocab.word_to_index(word_c)] if vocab.word_to_index(word_c) != -1 else None\n\n    if vec_a is None or vec_b is None or vec_c is None:\n        return f\"One of the words '{word_a}', '{word_b}', or '{word_c}' is not in the vocabulary.\"\n\n    # Word analogy: vector equation (vec_d = vec_a - vec_b + vec_c)\n    target_vec = vec_a - vec_b + vec_c\n    similarities = []\n\n    for idx in range(vocab.vocab_size):\n        other_word_vector = model.W[idx]\n        sim_score = cosine_similarity(target_vec, other_word_vector)\n        similarities.append((vocab.index_to_word(idx), sim_score))\n\n    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n\n    filtered_similarities = [word for word in similarities if word[0] not in {word_a, word_b, word_c}]\n\n    return filtered_similarities[0] if filtered_similarities else None\n\n# Example usage:\nanalogy_result = find_analogy(\"مرد\", \"شاه\", \"زن\", vocab, word2vec_model)\nprint(analogy_result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T13:56:29.941536Z","iopub.execute_input":"2025-05-15T13:56:29.941935Z","iopub.status.idle":"2025-05-15T13:56:29.952056Z","shell.execute_reply.started":"2025-05-15T13:56:29.941909Z","shell.execute_reply":"2025-05-15T13:56:29.951108Z"}},"outputs":[{"name":"stdout","text":"('کمک', 0.09306850703985767)\n","output_type":"stream"}],"execution_count":32}]}